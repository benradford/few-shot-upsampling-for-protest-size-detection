{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training examples from raw data: 2694\n",
      "Training examples after removing unmatched size_text strings: 2694\n",
      "Span tune examples in raw data: 25\n",
      "Span tune examples after removing unmatched size_text strings: 25\n",
      "Testing examples from raw data: 930\n",
      "Testing examples after removing unmatched size_text strings: 925\n",
      "Valid examples from raw data: 200\n",
      "Valid examples after removing unmatched size_text strings: 200\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import re\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pprint import pprint\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "from transformers import RobertaTokenizer, RobertaTokenizerFast, TFRobertaModel\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "np.random.seed(1234)\n",
    "\n",
    "seq_len = 450\n",
    "max_len = 512\n",
    "\n",
    "###################\n",
    "## TRAINING DATA ##\n",
    "###################\n",
    "ccc_train = []\n",
    "\n",
    "with open('/home/ben/GDrive/Projects/distant_crowds/data/ccc_train.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "for json_str in json_list:\n",
    "    ccc_train.append(json.loads(json_str))\n",
    "\n",
    "for ex in ccc_train:\n",
    "    ex[\"text\"] = \" \".join(ex[\"text\"].split())\n",
    "    ex[\"size_text\"] = \" \".join(ex[\"size_text\"].split())\n",
    "\n",
    "print(f\"Training examples from raw data: {len(ccc_train)}\")\n",
    "# ccc_train = [a for a in ccc_train if a[\"size_text\"].lower() in a[\"text\"].lower()]\n",
    "print(f\"Training examples after removing unmatched size_text strings: {len(ccc_train)}\")\n",
    "\n",
    "\n",
    "######################\n",
    "## SPAN TUNING DATA ##\n",
    "######################\n",
    "ccc_tune = []\n",
    "\n",
    "with open('../data/ccc_span_tune.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "for json_str in json_list:\n",
    "    ccc_tune.append(json.loads(json_str))\n",
    "\n",
    "for ex in ccc_tune:\n",
    "    ex[\"para\"] = \" \".join(ex[\"para\"].split())\n",
    "    ex[\"size_text\"] = \" \".join(ex[\"size_text\"].split())    \n",
    "\n",
    "print(f\"Span tune examples in raw data: {len(ccc_tune)}\")\n",
    "ccc_tune = [a for a in ccc_tune if a[\"size_text\"].lower() in a[\"para\"].lower()]\n",
    "print(f\"Span tune examples after removing unmatched size_text strings: {len(ccc_tune)}\")\n",
    "\n",
    "ccc_tune = {\"data\":[{\"paragraphs\":[{\"context\":qq[\"para\"],\n",
    "                             \"qas\":[\n",
    "                                 {\"answers\":[{\"answer_start\":qq[\"para\"].lower().index(qq[\"size_text\"].lower()),\n",
    "                                              \"text\":qq[\"size_text\"]}],\n",
    "                                  \"question\":\"How many people protested?\"}\n",
    "                             ]}]} for qq in ccc_tune]}\n",
    "\n",
    "##################\n",
    "## TESTING DATA ##\n",
    "##################\n",
    "ccc_test = []\n",
    "\n",
    "with open('../data/ccc_test_set.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "for json_str in json_list:\n",
    "    ccc_test.append(json.loads(json_str))\n",
    "    \n",
    "for ex in ccc_test:\n",
    "    ex[\"text\"] = \" \".join(ex[\"text\"].split())\n",
    "    ex[\"size_text\"] = \" \".join(ex[\"size_text\"].split())\n",
    "    \n",
    "print(f\"Testing examples from raw data: {len(ccc_test)}\")\n",
    "ccc_test = [a for a in ccc_test if a[\"size_text\"].lower() in a[\"text\"].lower()]\n",
    "print(f\"Testing examples after removing unmatched size_text strings: {len(ccc_test)}\")\n",
    "\n",
    "ccc_test = {\"data\":[{\"paragraphs\":[{\"context\":\" \".join(qq[\"text\"].split()),\n",
    "                             \"qas\":[\n",
    "                                 {\"answers\":[{\"answer_start\":qq[\"text\"].lower().index(qq[\"size_text\"].lower()),\n",
    "                                              \"text\":qq[\"size_text\"]}],\n",
    "                                  \"question\":\"How many people protested?\"}\n",
    "                             ]}]} for qq in ccc_test]}\n",
    "\n",
    "#####################\n",
    "## VALIDATION DATA ##\n",
    "#####################\n",
    "ccc_valid = []\n",
    "\n",
    "with open('../data/ccc_validation_set.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "for json_str in json_list:\n",
    "    ccc_valid.append(json.loads(json_str))\n",
    "    \n",
    "for ex in ccc_valid:\n",
    "    ex[\"text\"] = \" \".join(ex[\"text\"].split())\n",
    "    ex[\"size_text\"] = \" \".join(ex[\"size_text\"].split())\n",
    "    \n",
    "print(f\"Valid examples from raw data: {len(ccc_valid)}\")\n",
    "ccc_valid = [a for a in ccc_valid if a[\"size_text\"].lower() in a[\"text\"].lower()]\n",
    "print(f\"Valid examples after removing unmatched size_text strings: {len(ccc_valid)}\")\n",
    "\n",
    "ccc_valid = {\"data\":[{\"paragraphs\":[{\"context\":\" \".join(qq[\"text\"].split()),\n",
    "                             \"qas\":[\n",
    "                                 {\"answers\":[{\"answer_start\":qq[\"text\"].lower().index(qq[\"size_text\"].lower()),\n",
    "                                              \"text\":qq[\"size_text\"]}],\n",
    "                                  \"question\":\"How many people protested?\"}\n",
    "                             ]}]} for qq in ccc_valid]}\n",
    "\n",
    "########################\n",
    "## SOFT-LABELED TRAIN ##\n",
    "########################\n",
    "soft_train = []\n",
    "\n",
    "with open('../data/soft_labeled_train.jsonl', 'r') as json_file:\n",
    "    json_list = list(json_file)\n",
    "for json_str in json_list:\n",
    "    soft_train.append(json.loads(json_str))\n",
    "    \n",
    "for ex in soft_train:\n",
    "    ex[\"context\"] = \" \".join(ex[\"context\"].split())\n",
    "    ex[\"labeled_text\"] = \" \".join(ex[\"labeled_text\"].split())\n",
    "    \n",
    "# print(f\"Soft examples from raw data: {len(soft_train)}\")\n",
    "# soft_train = [a for a in soft_train if a[\"labeled_text\"].lower() in a[\"context\"].lower()]\n",
    "# print(f\"Soft examples after removing unmatched size_text strings: {len(soft_train)}\")\n",
    "\n",
    "# soft_train = {\"data\":[{\"paragraphs\":[{\"context\":\" \".join(qq[\"context\"].split()),\n",
    "#                              \"qas\":[\n",
    "#                                  {\"answers\":[{\"answer_start\":qq[\"context\"].lower().index(qq[\"labeled_text\"].lower()),\n",
    "#                                               \"text\":qq[\"labeled_text\"]}],\n",
    "#                                   \"question\":\"How many people protested?\"}\n",
    "#                              ]}]} for qq in soft_train]}\n",
    "\n",
    "#########################\n",
    "## TOKENIZER AND MODEL ##\n",
    "#########################\n",
    "\n",
    "tokenizer = RobertaTokenizerFast.from_pretrained(\"roberta-base\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1134 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "606\n"
     ]
    }
   ],
   "source": [
    "x_cat_inputs = []\n",
    "x_cat_attentions = []\n",
    "x_cat_types = []\n",
    "y_cat = []\n",
    "y_start = []\n",
    "y_end = []\n",
    "\n",
    "for ii, ex in enumerate(ccc_train):\n",
    "    text = ex[\"text\"]\n",
    "    answer = soft_train[ii][\"labeled_text\"]\n",
    "    \n",
    "    tokenized_context = tokenizer(text, return_offsets_mapping=True)\n",
    "    tokenized_question = tokenizer(\"</s> How many people protested?\", return_offsets_mapping=True)\n",
    "    \n",
    "    if len(tokenized_context.input_ids) > seq_len:\n",
    "        continue\n",
    "    \n",
    "    ########################\n",
    "    ## MERGE IN SOFT SPAN ##\n",
    "    ########################\n",
    "    try:\n",
    "        start_char_idx = text.lower().index(answer.lower())\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # Find end character index of answer in context\n",
    "    end_char_idx = start_char_idx + len(answer)\n",
    "\n",
    "    # Mark the character indexes in context that are in answer\n",
    "    is_char_in_ans = [0] * len(text)\n",
    "    for idx in range(start_char_idx, end_char_idx):\n",
    "        is_char_in_ans[idx] = 1\n",
    "\n",
    "    # Find tokens that were created from answer characters\n",
    "    ans_token_idx = []\n",
    "    for idx, (start, end) in enumerate(tokenized_context.offset_mapping):\n",
    "        if sum(is_char_in_ans[start:end]) > 0:\n",
    "            ans_token_idx.append(idx)\n",
    "\n",
    "    # Find start and end token index for tokens from answer\n",
    "    start_token_idx = ans_token_idx[0]\n",
    "    end_token_idx = ans_token_idx[-1]\n",
    "    y_start.append(start_token_idx)\n",
    "    y_end.append(end_token_idx)\n",
    "    #######################\n",
    "    ##                   ##\n",
    "    #######################                                    \n",
    "    \n",
    "    context_ids = tokenized_context.input_ids[0:-1]\n",
    "    question_ids = tokenized_question.input_ids[1:]\n",
    "    input_ids = context_ids + question_ids\n",
    "    \n",
    "    padding = [0]*(max_len - len(input_ids))\n",
    "    \n",
    "    input_ids = input_ids + (np.array(padding)+1).tolist()\n",
    "    attention_mask = [1]*len(context_ids) + [1]*len(question_ids) + [0]*len(padding)\n",
    "    token_type_ids = [0]*len(context_ids) + [1]*len(question_ids) + [1]*len(padding)\n",
    "    \n",
    "    x_cat_inputs.append(input_ids)\n",
    "    x_cat_attentions.append(attention_mask)\n",
    "    x_cat_types.append(token_type_ids)\n",
    "    y_cat.append(ex[\"size_cat\"])\n",
    "\n",
    "x_cat = (np.array(x_cat_inputs),\n",
    "         np.array(x_cat_types),\n",
    "         np.array(x_cat_attentions))\n",
    "y_cat = (np.array(y_cat),\n",
    "         np.array(y_start),\n",
    "         np.array(y_end))\n",
    "print(len(x_cat_inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 docs, (25, 512) span points created.\n",
      "925 docs, (3306, 512) test points created.\n",
      "200 docs, (725, 512) valid points created.\n"
     ]
    }
   ],
   "source": [
    "class SquadExample:\n",
    "    def __init__(self, question, context, start_char_idx, answer_text, all_answers, seq_len, max_len):\n",
    "        \n",
    "        # Clean context, answer and question\n",
    "        context = \" \".join(str(context).split())\n",
    "        question = \" \".join(str(question).split())\n",
    "        answer = \" \".join(str(answer_text).split())\n",
    "\n",
    "        self.question = str(question)\n",
    "        self.context = str(context)\n",
    "        self.start_char_idx = start_char_idx\n",
    "        self.answer_text = str(answer)\n",
    "        self.all_answers = all_answers\n",
    "        self.max_len = max_len\n",
    "        self.seq_len = seq_len\n",
    "        self.skip_doc = False\n",
    "        \n",
    "        self.input_ids = None\n",
    "        self.attention_mask = None\n",
    "        self.token_type_ids = None\n",
    "        self.start_token_idx = None\n",
    "        self.end_token_idx = None\n",
    "        self.skip = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        print(np.stack(self.input_ids).shape)\n",
    "        print(np.stack(self.token_type_ids).shape)\n",
    "        print(np.stack(self.attention_mask).shape)\n",
    "        return \"<SquadExample>\"\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return repr({\"input_ids\":self.input_ids, \n",
    "                     \"token_type_ids\":self.token_type_ids, \n",
    "                     \"attention_mask\":self.attention_mask,\n",
    "                     \"start_token_idx\":self.start_token_idx,\n",
    "                     \"end_token_idx\":self.end_token_idx,\n",
    "                     \"skip\":self.skip})\n",
    "\n",
    "    def preprocess(self):\n",
    "        context = self.context\n",
    "        question = self.question\n",
    "        answer = self.answer_text\n",
    "        start_char_idx = self.start_char_idx\n",
    "\n",
    "        # Find end character index of answer in context\n",
    "        end_char_idx = start_char_idx + len(answer)\n",
    "        if (end_char_idx >= len(context)) or (start_char_idx < 0):\n",
    "            self.skip_doc = True\n",
    "            return\n",
    "\n",
    "        # Mark the character indexes in context that are in answer\n",
    "        is_char_in_ans = [0] * len(context)\n",
    "        for idx in range(start_char_idx, end_char_idx):\n",
    "            is_char_in_ans[idx] = 1\n",
    "            \n",
    "        # Tokenize context\n",
    "        tokenized_context = tokenizer(context, return_offsets_mapping=True)\n",
    "        \n",
    "        context_input_ids = tokenized_context.input_ids\n",
    "        context_offset_mapping = tokenized_context.offset_mapping\n",
    "        context_attention_mask = tokenized_context.attention_mask\n",
    "        \n",
    "        self.context_input_ids = context_input_ids\n",
    "        self.context_offset_mapping = context_offset_mapping\n",
    "        \n",
    "        # Find tokens that were created from answer characters\n",
    "        ans_token_idx = []\n",
    "        for idx, (start, end) in enumerate(context_offset_mapping):\n",
    "            if sum(is_char_in_ans[start:end]) > 0:\n",
    "                ans_token_idx.append(idx)\n",
    "\n",
    "#         if len(ans_token_idx) == 0:\n",
    "#             self.skip_doc = True\n",
    "#             return\n",
    "        if (len(ans_token_idx) == 0):\n",
    "            ans_token_idx = [-1]\n",
    "\n",
    "        # Find start and end token index for tokens from answer\n",
    "        start_token_idx = ans_token_idx[0]\n",
    "        end_token_idx = ans_token_idx[-1]\n",
    "        \n",
    "        self.start_token_idx_master = start_token_idx\n",
    "        self.end_token_idx_master = end_token_idx\n",
    "        \n",
    "        # Tokenize question\n",
    "        tokenized_question = tokenizer(\"</s> \"+question, return_offsets_mapping=True)\n",
    "        \n",
    "        ## Crop start and end tokens\n",
    "        question_input_ids = tokenized_question.input_ids[1:]\n",
    "        context_input_ids = context_input_ids[1:-1]\n",
    "\n",
    "        ##\n",
    "        ## SPLIT UP CONTEXT INTO MULTIPLE QUESTIONS OF max_len\n",
    "        ##\n",
    "        \n",
    "        if seq_len >= len(context_input_ids):\n",
    "            offsets = [0]\n",
    "        else:\n",
    "            ii = 0\n",
    "            offsets = []\n",
    "            while (ii+seq_len) <= len(context_input_ids):\n",
    "                offsets.append(ii)\n",
    "                ii = ii + round(seq_len/2)\n",
    "            offsets = offsets + [len(context_input_ids)-seq_len]\n",
    "        \n",
    "        list_input_ids = []\n",
    "        list_start_token_idx = []\n",
    "        list_end_token_idx = []\n",
    "        list_attention_mask = []\n",
    "        list_token_type_ids = []\n",
    "        list_skip = []\n",
    "        \n",
    "        for ii in offsets:\n",
    "            subcontext_input_ids = [0]+context_input_ids[ii:(ii+seq_len)]+question_input_ids\n",
    "            subcontext_start_token_idx = start_token_idx - ii\n",
    "            subcontext_end_token_idx = end_token_idx - ii\n",
    "            subcontext_padding = [0] * (self.max_len - len(subcontext_input_ids))\n",
    "            \n",
    "            subcontext_attention_mask = [1] * len(subcontext_input_ids) + subcontext_padding\n",
    "            subcontext_token_type_ids = [0] + [0]*len(context_input_ids[ii:(ii+seq_len)]) + [1]*len(question_input_ids) + (np.array(subcontext_padding)+1).tolist()\n",
    "            subcontext_input_ids = subcontext_input_ids + (np.array(subcontext_padding)+1).tolist()\n",
    "            \n",
    "            if (subcontext_start_token_idx >= 0) and (subcontext_end_token_idx < seq_len):\n",
    "                skip = False\n",
    "            else:\n",
    "                subcontext_start_token_idx = 0\n",
    "                subcontext_end_token_idx = 0\n",
    "                skip = False\n",
    "                \n",
    "            list_input_ids.append(subcontext_input_ids)\n",
    "            list_attention_mask.append(subcontext_attention_mask)\n",
    "            list_token_type_ids.append(subcontext_token_type_ids)\n",
    "            list_start_token_idx.append(subcontext_start_token_idx)\n",
    "            list_end_token_idx.append(subcontext_end_token_idx)\n",
    "            list_skip.append(skip)\n",
    "        \n",
    "        self.input_ids = (list_input_ids)\n",
    "        self.attention_mask = (list_attention_mask)\n",
    "        self.token_type_ids = (list_token_type_ids)\n",
    "        self.start_token_idx = (list_start_token_idx)\n",
    "        self.end_token_idx = (list_end_token_idx)\n",
    "        self.skip = list_skip\n",
    "        self.example_offset = offsets\n",
    "        \n",
    "    def train_examples(self, include_impossible=False):\n",
    "        for idx, skip_ex in enumerate(self.skip):\n",
    "            if include_impossible is False:\n",
    "                if skip_ex is False:\n",
    "                    yield  {\"input_ids\":self.input_ids[idx],\n",
    "                            \"token_type_ids\":self.token_type_ids[idx],\n",
    "                            \"attention_mask\":self.attention_mask[idx],\n",
    "                            \"start_token_idx\":self.start_token_idx[idx],\n",
    "                            \"end_token_idx\":self.end_token_idx[idx]}\n",
    "            else:\n",
    "                yield  {\"input_ids\":self.input_ids[idx],\n",
    "                            \"token_type_ids\":self.token_type_ids[idx],\n",
    "                            \"attention_mask\":self.attention_mask[idx],\n",
    "                            \"start_token_idx\":self.start_token_idx[idx],\n",
    "                            \"end_token_idx\":self.end_token_idx[idx]}\n",
    "    \n",
    "    \n",
    "    def inference_from_onehot(self, pred_start, pred_end):\n",
    "\n",
    "#         if force_answer == False:\n",
    "        if (np.max(np.argmax(pred_start, axis=1)) == 0) and (np.max(np.argmax(pred_end, axis=1)) == 0):\n",
    "            return(\"\", {\"all_answers\":self.all_answers,\n",
    "                        \"start_token_pred\":-1, \n",
    "                        \"end_token_pred\":-1, \n",
    "                        \"start_char_pred\":-1, \n",
    "                        \"end_char_pred\":-1,\n",
    "                        \"start_token\":self.start_token_idx_master,\n",
    "                        \"end_token\":self.end_token_idx_master,\n",
    "                        \"tokens_pred\":set(list([])),\n",
    "                        \"tokens\":set(list(range(self.start_token_idx_master,(self.end_token_idx_master+1))))})\n",
    "        \n",
    "        seq_len = min(self.seq_len, len(self.context_input_ids))\n",
    "        \n",
    "        pred_start_matrix = np.zeros((len(self.input_ids), len(self.context_input_ids)))\n",
    "        pred_end_matrix = np.zeros((len(self.input_ids), len(self.context_input_ids)))\n",
    "        \n",
    "        for idx, value in enumerate(pred_start):\n",
    "            offset = self.example_offset[idx]+1\n",
    "            pred_start_sub = pred_start[idx][1:seq_len]\n",
    "            pred_end_sub   = pred_end[idx][1:seq_len]\n",
    "            pred_start_matrix[idx,(offset):(offset+seq_len-1)] = pred_start_sub\n",
    "            pred_end_matrix[idx,(offset):(offset+seq_len-1)] = pred_end_sub\n",
    "            \n",
    "        highest_prob = np.argmax(np.max(pred_start_matrix, axis=1) + np.max(pred_end_matrix, axis=1))\n",
    "        \n",
    "        top_start = np.argmax(pred_start_matrix[highest_prob,:])\n",
    "        top_end   = np.argmax(pred_end_matrix[highest_prob,:])\n",
    "        \n",
    "#         pred_start = np.max(pred_start_matrix, axis=0)\n",
    "#         pred_end   = np.max(pred_end_matrix, axis=0)\n",
    "        \n",
    "#         top_start = np.argmax(pred_start)\n",
    "#         top_end = np.argmax(pred_end)\n",
    "        \n",
    "        start_char = self.context_offset_mapping[top_start][0]\n",
    "        end_char = self.context_offset_mapping[top_end][1]\n",
    "        \n",
    "        return (self.context[start_char:end_char], {\"all_answers\":self.all_answers,\n",
    "                                                    \"start_token_pred\":top_start, \n",
    "                                                    \"end_token_pred\":top_end, \n",
    "                                                    \"start_char_pred\":start_char, \n",
    "                                                    \"end_char_pred\":end_char,\n",
    "                                                    \"start_token\":self.start_token_idx_master,\n",
    "                                                    \"end_token\":self.end_token_idx_master,\n",
    "                                                    \"tokens_pred\":set(list(range(top_start,(top_end+1)))),\n",
    "                                                    \"tokens\":set(list(range(self.start_token_idx_master,(self.end_token_idx_master+1))))})\n",
    "                \n",
    "    def model_inference(self, model):\n",
    "        pred = model.predict([np.stack(self.input_ids),\n",
    "                      np.stack(self.attention_mask),\n",
    "                      np.stack(self.token_type_ids)], batch_size=8)\n",
    "        pred_start = pred[0]\n",
    "        pred_end   = pred[1]\n",
    "        \n",
    "        return self.inference_from_onehot(pred_start, pred_end)\n",
    "    \n",
    "    def fake_inference(self):\n",
    "        pred_start_mat = []\n",
    "        pred_end_mat = []\n",
    "        for idx, val in enumerate(self.start_token_idx):\n",
    "            pred_start = np.zeros_like(np.array(self.input_ids[idx]))\n",
    "            pred_end = np.zeros_like(np.array(self.input_ids[idx]))\n",
    "            if self.skip[idx] == False:\n",
    "                pred_start[val] = 1.0\n",
    "                pred_end[self.end_token_idx[idx]] = 1.0\n",
    "            pred_start_mat.append(pred_start)\n",
    "            pred_end_mat.append(pred_end)\n",
    "            \n",
    "        pred_start_mat = np.array(pred_start_mat)\n",
    "        pred_end_mat = np.array(pred_end_mat)\n",
    "        \n",
    "        return self.inference_from_onehot(pred_start_mat,pred_end_mat)\n",
    "        \n",
    "\n",
    "def create_squad_examples(raw_data, seq_len, max_len):\n",
    "    squad_examples = []\n",
    "    for item in raw_data[\"data\"]:\n",
    "        for para in item[\"paragraphs\"]:\n",
    "            context = para[\"context\"]\n",
    "            for qa in para[\"qas\"]:\n",
    "                if len(qa[\"answers\"]) > 0:\n",
    "                    question = qa[\"question\"]\n",
    "                    answer_text = qa[\"answers\"][0][\"text\"]\n",
    "                    all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
    "                    start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
    "                    squad_eg = SquadExample(\n",
    "                        question, context, start_char_idx, answer_text, all_answers, seq_len, max_len\n",
    "                    )\n",
    "                    squad_eg.preprocess()\n",
    "                    squad_examples.append(squad_eg)\n",
    "                else:\n",
    "                    question = qa[\"question\"]\n",
    "                    answer_text = \"\"\n",
    "                    all_answers = [\"\"]\n",
    "                    start_char_idx = 0\n",
    "                    squad_eg = SquadExample(\n",
    "                        question, context, start_char_idx, answer_text, all_answers, seq_len, max_len\n",
    "                    )\n",
    "                    squad_eg.preprocess()\n",
    "                    squad_examples.append(squad_eg)\n",
    "    return squad_examples\n",
    "\n",
    "\n",
    "def create_inputs_targets(squad_examples, include_impossible=False):\n",
    "    dataset_dict = {\n",
    "        \"input_ids\": [],\n",
    "        \"token_type_ids\": [],\n",
    "        \"attention_mask\": [],\n",
    "        \"start_token_idx\": [],\n",
    "        \"end_token_idx\": [],\n",
    "    }\n",
    "    for item in squad_examples:\n",
    "        if item.skip_doc is False:\n",
    "            for example in item.train_examples(include_impossible):\n",
    "                for key in dataset_dict:\n",
    "                    dataset_dict[key].append(np.array(example[key]))\n",
    "    for key in dataset_dict:\n",
    "        dataset_dict[key] = np.array(dataset_dict[key])\n",
    "\n",
    "    x = (\n",
    "        dataset_dict[\"input_ids\"],\n",
    "        dataset_dict[\"token_type_ids\"],\n",
    "        dataset_dict[\"attention_mask\"])\n",
    "    y = (dataset_dict[\"start_token_idx\"], dataset_dict[\"end_token_idx\"])\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def merge_squad_results(squad_examples, start_preds, end_preds):\n",
    "    ii = 0\n",
    "    tally = []\n",
    "    answers = []\n",
    "    f1_list = []\n",
    "    for ex in squad_examples:\n",
    "        if ex.skip_doc is False:\n",
    "            n_sub = len(ex.skip)\n",
    "            pred_out = ex.inference_from_onehot(start_preds[ii:(ii+n_sub),:], end_preds[ii:(ii+n_sub),:])\n",
    "            tally.append(pred_out[0].lower() in [a.lower() for a in ex.all_answers])\n",
    "            answers.append(pred_out)\n",
    "            tp = len(pred_out[1][\"tokens_pred\"].intersection(pred_out[1][\"tokens\"]))\n",
    "            fp = len(pred_out[1][\"tokens_pred\"].difference(pred_out[1][\"tokens\"]))\n",
    "            fn = len(pred_out[1][\"tokens\"].difference(pred_out[1][\"tokens_pred\"]))\n",
    "            ii = ii + n_sub\n",
    "            if tp>0:\n",
    "                precision = tp/(tp+fp)\n",
    "                recall=tp/(tp+fn)\n",
    "                f1_list.append((2*precision*recall)/(precision+recall))\n",
    "            else:\n",
    "                f1_list.append(0)\n",
    "    return (np.mean(tally), \n",
    "            np.mean(f1_list), \n",
    "            answers)\n",
    "\n",
    "\n",
    "# train_squad_examples = create_squad_examples(raw_train_data, seq_len, max_len)\n",
    "# x_train, y_train = create_inputs_targets(train_squad_examples)\n",
    "# print(f\"{len(train_squad_examples)} docs, {x_train.shape[0]} training points created.\")\n",
    "\n",
    "\n",
    "span_examples = create_squad_examples(ccc_tune, seq_len, max_len)\n",
    "x_span, y_span = create_inputs_targets(span_examples)\n",
    "print(f\"{len(span_examples)} docs, {x_span[0].shape} span points created.\")\n",
    "\n",
    "test_examples = create_squad_examples(ccc_test, seq_len, max_len)\n",
    "x_test, y_test = create_inputs_targets(test_examples)\n",
    "print(f\"{len(test_examples)} docs, {x_test[0].shape} test points created.\")\n",
    "\n",
    "valid_examples = create_squad_examples(ccc_valid, seq_len, max_len)\n",
    "x_valid, y_valid = create_inputs_targets(valid_examples)\n",
    "print(f\"{len(valid_examples)} docs, {x_valid[0].shape} valid points created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roberta (TFRobertaMainLayer)    {'pooler_output': (N 124645632   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_logit (Dense)             (None, 512, 1)       768         roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "end_logit (Dense)               (None, 512, 1)       768         roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           start_logit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           end_logit[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512)          0           flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 124,647,168\n",
      "Trainable params: 124,647,168\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 512)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "roberta (TFRobertaMainLayer)    {'pooler_output': (N 124645632   input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "start_logit (Dense)             (None, 512, 1)       768         roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "end_logit (Dense)               (None, 512, 1)       768         roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 512)          0           start_logit[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 512)          0           end_logit[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 512)          0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 512)          0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 512)          0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activity_regularization (Activi (None, 512)          0           lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 512, 1)       0           activity_regularization[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 512, 768)     0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 512, 768)     0           lambda_1[0][0]                   \n",
      "                                                                 roberta[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 768)          0           multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1)            769         global_max_pooling1d[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 124,647,937\n",
      "Trainable params: 124,647,937\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))\n",
    "\n",
    "with strategy.scope():\n",
    "    model = keras.models.load_model('./roberta_base_squad2_512in')\n",
    "model.summary()\n",
    "\n",
    "def makeMask(x):\n",
    "    x_cumsum = tf.math.cumsum(x[0], axis=1)\n",
    "    y_cumsum = tf.math.cumsum(x[1], axis=1, reverse=True)\n",
    "    prod = tf.math.multiply(x_cumsum, y_cumsum)\n",
    "    return prod\n",
    "\n",
    "# def makeMask(x):\n",
    "#     x_argmax = tf.math.argmax(x[0], axis=1)\n",
    "#     y_argmax = tf.math.argmax(x[1], axis=1)\n",
    "#     x_onehot = tf.one_hot(x_argmax, 512, axis=1)\n",
    "#     y_onehot = tf.one_hot(y_argmax, 512, axis=1)\n",
    "#     x_cumsum = tf.cumsum(x_onehot, axis=1)\n",
    "#     y_cumsum = tf.cumsum(y_onehot, axis=1, reverse=True)\n",
    "#     prod = tf.math.multiply(x_cumsum,y_cumsum)\n",
    "#     return prod\n",
    "\n",
    "def expandDims(x):\n",
    "    return tf.expand_dims(x,2)\n",
    "\n",
    "with strategy.scope():\n",
    "    out_start = model.get_layer(\"activation_4\").output\n",
    "    out_end = model.get_layer(\"activation_5\").output\n",
    "    span_mask = layers.ActivityRegularization(l1=0.01)(layers.Lambda(makeMask)([out_start,out_end]))\n",
    "    span_mask_2d = layers.Lambda(tf.tile, arguments={'multiples':(1,1,768)})(layers.Lambda(expandDims)(span_mask))\n",
    "    roberta_embedding = model.get_layer(\"roberta\").output[\"last_hidden_state\"]\n",
    "    masked_embedding = layers.Multiply()([span_mask_2d,roberta_embedding])\n",
    "    \n",
    "    avg_layer = layers.GlobalMaxPooling1D(data_format=\"channels_last\")(masked_embedding)\n",
    "    out_count = layers.Dense(1, activation=\"linear\")(avg_layer)\n",
    "\n",
    "    new_optimizer = keras.optimizers.Adam(lr=(5e-5))\n",
    "    model_cat = keras.models.Model(inputs=[model.input],outputs=[out_count, out_start, out_end])\n",
    "    model_cat.compile(optimizer=new_optimizer, \n",
    "                      loss=[\"mean_squared_error\",\n",
    "                            \"sparse_categorical_crossentropy\",\n",
    "                            \"sparse_categorical_crossentropy\"])\n",
    "    \n",
    "    model_mask = keras.models.Model(inputs=[model.input],outputs=[span_mask])\n",
    "    \n",
    "model_cat.summary()\n",
    "\n",
    "keras.backend.set_value(model.optimizer.learning_rate, (5e-6))\n",
    "keras.backend.set_value(model_cat.optimizer.learning_rate, (5e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 6s 265ms/step\n",
      "92/92 [==============================] - 27s 294ms/step\n",
      "Validation set accuracy (EM): 0.19\n",
      "Test set accuracy (EM): 0.16972972972972972\n",
      "Validation set F1: 0.27271624189581933\n",
      "Test set F1: 0.2658847892310077\n"
     ]
    }
   ],
   "source": [
    "pred_start_v, pred_end_v = model.predict((x_valid[0], x_valid[1], x_valid[2]), batch_size=36, verbose=1)\n",
    "valid_acc = merge_squad_results(valid_examples, pred_start_v, pred_end_v)\n",
    "\n",
    "pred_start_t, pred_end_t = model.predict((x_test[0], x_test[1], x_test[2]), batch_size=36, verbose=1)\n",
    "test_acc = merge_squad_results(test_examples, pred_start_t, pred_end_t)\n",
    "\n",
    "print(f\"Validation set accuracy (EM): {valid_acc[0]}\")\n",
    "print(f\"Test set accuracy (EM): {test_acc[0]}\")\n",
    "print(f\"Validation set F1: {valid_acc[1]}\")\n",
    "print(f\"Test set F1: {test_acc[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITERATION: 0 of 75.\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7efd8c4c4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7efd8c4c4400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "INFO:tensorflow:batch_all_reduce: 200 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 200 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 3 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 10.7382 - activation_4_loss: 3.6161 - activation_5_loss: 4.7360 - dense_loss: 2.2626\n",
      "1/1 [==============================] - 9s 9s/step - loss: 1.7037 - activation_4_loss: 1.3146 - activation_5_loss: 0.3891 - val_loss: 4.1687 - val_activation_4_loss: 1.2592 - val_activation_5_loss: 2.9095\n",
      "ITERATION: 1 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3724 - activation_4_loss: 1.9114 - activation_5_loss: 3.0707 - dense_loss: 2.1891\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.4219 - activation_4_loss: 1.0460 - activation_5_loss: 0.3759 - val_loss: 4.2783 - val_activation_4_loss: 1.2960 - val_activation_5_loss: 2.9823\n",
      "ITERATION: 2 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.8717 - activation_4_loss: 1.9143 - activation_5_loss: 1.4670 - dense_loss: 2.3454\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.3877 - activation_4_loss: 1.0566 - activation_5_loss: 0.3311 - val_loss: 4.4863 - val_activation_4_loss: 1.3838 - val_activation_5_loss: 3.1025\n",
      "ITERATION: 3 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.5464 - activation_4_loss: 2.0712 - activation_5_loss: 2.4145 - dense_loss: 3.8838\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.6330 - activation_4_loss: 1.3064 - activation_5_loss: 0.3265 - val_loss: 4.7189 - val_activation_4_loss: 1.4885 - val_activation_5_loss: 3.2303\n",
      "ITERATION: 4 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2818 - activation_4_loss: 1.9609 - activation_5_loss: 2.4398 - dense_loss: 1.7251\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.3398 - activation_4_loss: 1.0187 - activation_5_loss: 0.3212 - val_loss: 4.9733 - val_activation_4_loss: 1.6087 - val_activation_5_loss: 3.3646\n",
      "ITERATION: 5 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.9528 - activation_4_loss: 2.0391 - activation_5_loss: 1.7592 - dense_loss: 3.8392\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9236 - activation_4_loss: 0.7130 - activation_5_loss: 0.2106 - val_loss: 5.2324 - val_activation_4_loss: 1.7295 - val_activation_5_loss: 3.5029\n",
      "ITERATION: 6 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6966 - activation_4_loss: 2.3788 - activation_5_loss: 1.6443 - dense_loss: 1.5485\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6614 - activation_4_loss: 0.5241 - activation_5_loss: 0.1373 - val_loss: 5.4770 - val_activation_4_loss: 1.8446 - val_activation_5_loss: 3.6324\n",
      "ITERATION: 7 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6625 - activation_4_loss: 1.5981 - activation_5_loss: 2.7329 - dense_loss: 2.2135\n",
      "1/1 [==============================] - 6s 6s/step - loss: 1.2573 - activation_4_loss: 1.0508 - activation_5_loss: 0.2065 - val_loss: 5.7155 - val_activation_4_loss: 1.9594 - val_activation_5_loss: 3.7561\n",
      "ITERATION: 8 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4120 - activation_4_loss: 1.0079 - activation_5_loss: 0.8102 - dense_loss: 1.4619\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.6492 - activation_4_loss: 0.5677 - activation_5_loss: 0.0814 - val_loss: 5.9520 - val_activation_4_loss: 2.0719 - val_activation_5_loss: 3.8801\n",
      "ITERATION: 9 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1174 - activation_4_loss: 0.7235 - activation_5_loss: 1.3030 - dense_loss: 1.9338\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5844 - activation_4_loss: 0.4433 - activation_5_loss: 0.1411 - val_loss: 6.1825 - val_activation_4_loss: 2.1785 - val_activation_5_loss: 4.0040\n",
      "ITERATION: 10 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9077 - activation_4_loss: 1.3399 - activation_5_loss: 2.4356 - dense_loss: 1.9188\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3781 - activation_4_loss: 0.2708 - activation_5_loss: 0.1074 - val_loss: 6.4031 - val_activation_4_loss: 2.2799 - val_activation_5_loss: 4.1233\n",
      "ITERATION: 11 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0454 - activation_4_loss: 1.7057 - activation_5_loss: 1.4331 - dense_loss: 1.7651\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4446 - activation_4_loss: 0.4085 - activation_5_loss: 0.0361 - val_loss: 6.6250 - val_activation_4_loss: 2.3827 - val_activation_5_loss: 4.2422\n",
      "ITERATION: 12 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 8.8100 - activation_4_loss: 2.3202 - activation_5_loss: 4.1564 - dense_loss: 2.0771\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.5750 - activation_4_loss: 0.4393 - activation_5_loss: 0.1357 - val_loss: 6.8231 - val_activation_4_loss: 2.4762 - val_activation_5_loss: 4.3469\n",
      "ITERATION: 13 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.6564 - activation_4_loss: 1.1761 - activation_5_loss: 1.7078 - dense_loss: 1.6446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 0.5690 - activation_4_loss: 0.4395 - activation_5_loss: 0.1295 - val_loss: 7.0133 - val_activation_4_loss: 2.5665 - val_activation_5_loss: 4.4468\n",
      "ITERATION: 14 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6773 - activation_4_loss: 2.2453 - activation_5_loss: 2.1639 - dense_loss: 1.0967\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.9126 - activation_4_loss: 0.7384 - activation_5_loss: 0.1742 - val_loss: 7.2069 - val_activation_4_loss: 2.6602 - val_activation_5_loss: 4.5467\n",
      "ITERATION: 15 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.4475 - activation_4_loss: 2.0115 - activation_5_loss: 2.6984 - dense_loss: 1.6599\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1849 - activation_4_loss: 0.1528 - activation_5_loss: 0.0321 - val_loss: 7.3903 - val_activation_4_loss: 2.7519 - val_activation_5_loss: 4.6384\n",
      "ITERATION: 16 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.2430 - activation_4_loss: 1.3629 - activation_5_loss: 3.1462 - dense_loss: 1.6334\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2829 - activation_4_loss: 0.2486 - activation_5_loss: 0.0343 - val_loss: 7.5611 - val_activation_4_loss: 2.8393 - val_activation_5_loss: 4.7218\n",
      "ITERATION: 17 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8498 - activation_4_loss: 0.8980 - activation_5_loss: 1.7701 - dense_loss: 1.0545\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2565 - activation_4_loss: 0.1930 - activation_5_loss: 0.0635 - val_loss: 7.7178 - val_activation_4_loss: 2.9191 - val_activation_5_loss: 4.7986\n",
      "ITERATION: 18 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3235 - activation_4_loss: 0.8817 - activation_5_loss: 1.8635 - dense_loss: 1.4485\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2439 - activation_4_loss: 0.2109 - activation_5_loss: 0.0330 - val_loss: 7.8733 - val_activation_4_loss: 2.9987 - val_activation_5_loss: 4.8747\n",
      "ITERATION: 19 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.2595 - activation_4_loss: 1.0443 - activation_5_loss: 1.8337 - dense_loss: 1.2856\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3454 - activation_4_loss: 0.2692 - activation_5_loss: 0.0762 - val_loss: 8.0312 - val_activation_4_loss: 3.0794 - val_activation_5_loss: 4.9517\n",
      "ITERATION: 20 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.3252 - activation_4_loss: 0.8497 - activation_5_loss: 0.6912 - dense_loss: 1.5931\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4486 - activation_4_loss: 0.3745 - activation_5_loss: 0.0740 - val_loss: 8.1724 - val_activation_4_loss: 3.1491 - val_activation_5_loss: 5.0233\n",
      "ITERATION: 21 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6408 - activation_4_loss: 1.7467 - activation_5_loss: 2.2265 - dense_loss: 1.4319\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1707 - activation_4_loss: 0.1374 - activation_5_loss: 0.0333 - val_loss: 8.3048 - val_activation_4_loss: 3.2142 - val_activation_5_loss: 5.0906\n",
      "ITERATION: 22 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7712 - activation_4_loss: 0.5075 - activation_5_loss: 0.9482 - dense_loss: 2.1554\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2274 - activation_4_loss: 0.1795 - activation_5_loss: 0.0479 - val_loss: 8.4277 - val_activation_4_loss: 3.2704 - val_activation_5_loss: 5.1573\n",
      "ITERATION: 23 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.9616 - activation_4_loss: 2.2139 - activation_5_loss: 2.6804 - dense_loss: 0.9393\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1306 - activation_4_loss: 0.1177 - activation_5_loss: 0.0128 - val_loss: 8.5471 - val_activation_4_loss: 3.3263 - val_activation_5_loss: 5.2208\n",
      "ITERATION: 24 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7066 - activation_4_loss: 0.8424 - activation_5_loss: 1.3974 - dense_loss: 1.2036\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4148 - activation_4_loss: 0.3816 - activation_5_loss: 0.0331 - val_loss: 8.6706 - val_activation_4_loss: 3.3826 - val_activation_5_loss: 5.2879\n",
      "ITERATION: 25 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.4592 - activation_4_loss: 2.3998 - activation_5_loss: 2.3792 - dense_loss: 0.6261\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.3929 - activation_4_loss: 0.3629 - activation_5_loss: 0.0300 - val_loss: 8.7778 - val_activation_4_loss: 3.4343 - val_activation_5_loss: 5.3435\n",
      "ITERATION: 26 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.8550 - activation_4_loss: 1.4444 - activation_5_loss: 0.8094 - dense_loss: 0.4942\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0694 - activation_4_loss: 0.0543 - activation_5_loss: 0.0151 - val_loss: 8.8831 - val_activation_4_loss: 3.4837 - val_activation_5_loss: 5.3994\n",
      "ITERATION: 27 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.8319 - activation_4_loss: 1.6350 - activation_5_loss: 1.1819 - dense_loss: 0.8861\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1614 - activation_4_loss: 0.1506 - activation_5_loss: 0.0108 - val_loss: 8.9806 - val_activation_4_loss: 3.5286 - val_activation_5_loss: 5.4521\n",
      "ITERATION: 28 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9040 - activation_4_loss: 1.2018 - activation_5_loss: 2.1782 - dense_loss: 0.4323\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0866 - activation_4_loss: 0.0549 - activation_5_loss: 0.0317 - val_loss: 9.0642 - val_activation_4_loss: 3.5684 - val_activation_5_loss: 5.4958\n",
      "ITERATION: 29 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0459 - activation_4_loss: 0.3285 - activation_5_loss: 0.7318 - dense_loss: 0.9110\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1178 - activation_4_loss: 0.1019 - activation_5_loss: 0.0159 - val_loss: 9.1460 - val_activation_4_loss: 3.6070 - val_activation_5_loss: 5.5390\n",
      "ITERATION: 30 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2867 - activation_4_loss: 1.2533 - activation_5_loss: 1.5963 - dense_loss: 0.3735\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2410 - activation_4_loss: 0.1769 - activation_5_loss: 0.0641 - val_loss: 9.2156 - val_activation_4_loss: 3.6405 - val_activation_5_loss: 5.5751\n",
      "ITERATION: 31 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.9276 - activation_4_loss: 2.2486 - activation_5_loss: 1.7479 - dense_loss: 0.7806\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1416 - activation_4_loss: 0.1253 - activation_5_loss: 0.0163 - val_loss: 9.2817 - val_activation_4_loss: 3.6717 - val_activation_5_loss: 5.6100\n",
      "ITERATION: 32 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.0197 - activation_4_loss: 1.6130 - activation_5_loss: 1.9223 - dense_loss: 0.4012\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0945 - activation_4_loss: 0.0865 - activation_5_loss: 0.0080 - val_loss: 9.3411 - val_activation_4_loss: 3.7027 - val_activation_5_loss: 5.6384\n",
      "ITERATION: 33 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 6.6067 - activation_4_loss: 1.9364 - activation_5_loss: 3.1417 - dense_loss: 1.3850\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1477 - activation_4_loss: 0.1397 - activation_5_loss: 0.0080 - val_loss: 9.3778 - val_activation_4_loss: 3.7256 - val_activation_5_loss: 5.6522\n",
      "ITERATION: 34 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.8204 - activation_4_loss: 0.6148 - activation_5_loss: 0.6511 - dense_loss: 0.5089\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1026 - activation_4_loss: 0.0841 - activation_5_loss: 0.0185 - val_loss: 9.4122 - val_activation_4_loss: 3.7469 - val_activation_5_loss: 5.6653\n",
      "ITERATION: 35 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1449 - activation_4_loss: 0.5525 - activation_5_loss: 1.2668 - dense_loss: 0.2545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 0.2145 - activation_4_loss: 0.1941 - activation_5_loss: 0.0204 - val_loss: 9.4455 - val_activation_4_loss: 3.7680 - val_activation_5_loss: 5.6776\n",
      "ITERATION: 36 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1585 - activation_4_loss: 1.5211 - activation_5_loss: 1.0465 - dense_loss: 0.5004\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2180 - activation_4_loss: 0.2075 - activation_5_loss: 0.0105 - val_loss: 9.4748 - val_activation_4_loss: 3.7867 - val_activation_5_loss: 5.6881\n",
      "ITERATION: 37 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.4388 - activation_4_loss: 1.5353 - activation_5_loss: 2.3943 - dense_loss: 0.4291\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1057 - activation_4_loss: 0.0972 - activation_5_loss: 0.0084 - val_loss: 9.4960 - val_activation_4_loss: 3.8041 - val_activation_5_loss: 5.6919\n",
      "ITERATION: 38 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.0302 - activation_4_loss: 0.5682 - activation_5_loss: 0.9001 - dense_loss: 0.4778\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1471 - activation_4_loss: 0.1325 - activation_5_loss: 0.0146 - val_loss: 9.5206 - val_activation_4_loss: 3.8231 - val_activation_5_loss: 5.6976\n",
      "ITERATION: 39 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1025 - activation_4_loss: 0.9226 - activation_5_loss: 1.5500 - dense_loss: 0.5449\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1124 - activation_4_loss: 0.0991 - activation_5_loss: 0.0133 - val_loss: 9.5373 - val_activation_4_loss: 3.8387 - val_activation_5_loss: 5.6987\n",
      "ITERATION: 40 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.1114 - activation_4_loss: 1.8505 - activation_5_loss: 1.6712 - dense_loss: 0.4655\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0588 - activation_4_loss: 0.0412 - activation_5_loss: 0.0176 - val_loss: 9.5380 - val_activation_4_loss: 3.8470 - val_activation_5_loss: 5.6910\n",
      "ITERATION: 41 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.2543 - activation_4_loss: 1.4972 - activation_5_loss: 1.0969 - dense_loss: 0.5420\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0772 - activation_4_loss: 0.0659 - activation_5_loss: 0.0113 - val_loss: 9.5465 - val_activation_4_loss: 3.8592 - val_activation_5_loss: 5.6873\n",
      "ITERATION: 42 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.3001 - activation_4_loss: 0.9461 - activation_5_loss: 0.8660 - dense_loss: 0.3775\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0557 - activation_4_loss: 0.0454 - activation_5_loss: 0.0103 - val_loss: 9.5576 - val_activation_4_loss: 3.8713 - val_activation_5_loss: 5.6862\n",
      "ITERATION: 43 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9362 - activation_4_loss: 0.4179 - activation_5_loss: 2.3588 - dense_loss: 0.1012\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1443 - activation_4_loss: 0.1316 - activation_5_loss: 0.0128 - val_loss: 9.5565 - val_activation_4_loss: 3.8804 - val_activation_5_loss: 5.6760\n",
      "ITERATION: 44 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1397 - activation_4_loss: 0.7094 - activation_5_loss: 0.9495 - dense_loss: 0.3939\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0966 - activation_4_loss: 0.0911 - activation_5_loss: 0.0055 - val_loss: 9.5540 - val_activation_4_loss: 3.8869 - val_activation_5_loss: 5.6671\n",
      "ITERATION: 45 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.7790 - activation_4_loss: 1.2824 - activation_5_loss: 1.0792 - dense_loss: 0.3502\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1132 - activation_4_loss: 0.1025 - activation_5_loss: 0.0106 - val_loss: 9.5409 - val_activation_4_loss: 3.8886 - val_activation_5_loss: 5.6523\n",
      "ITERATION: 46 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 7.3586 - activation_4_loss: 3.2971 - activation_5_loss: 3.5874 - dense_loss: 0.3006\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2119 - activation_4_loss: 0.1834 - activation_5_loss: 0.0286 - val_loss: 9.5051 - val_activation_4_loss: 3.8841 - val_activation_5_loss: 5.6210\n",
      "ITERATION: 47 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1903 - activation_4_loss: 0.8457 - activation_5_loss: 1.7962 - dense_loss: 0.4842\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0455 - activation_4_loss: 0.0351 - activation_5_loss: 0.0104 - val_loss: 9.4641 - val_activation_4_loss: 3.8776 - val_activation_5_loss: 5.5865\n",
      "ITERATION: 48 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3297 - activation_4_loss: 1.4567 - activation_5_loss: 2.1501 - dense_loss: 0.4984\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2168 - activation_4_loss: 0.2006 - activation_5_loss: 0.0162 - val_loss: 9.4223 - val_activation_4_loss: 3.8720 - val_activation_5_loss: 5.5503\n",
      "ITERATION: 49 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4792 - activation_4_loss: 0.7853 - activation_5_loss: 1.5385 - dense_loss: 1.0147\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0372 - activation_4_loss: 0.0291 - activation_5_loss: 0.0081 - val_loss: 9.3916 - val_activation_4_loss: 3.8702 - val_activation_5_loss: 5.5214\n",
      "ITERATION: 50 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5211 - activation_4_loss: 1.6234 - activation_5_loss: 1.6307 - dense_loss: 0.1436\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2883 - activation_4_loss: 0.2761 - activation_5_loss: 0.0121 - val_loss: 9.3655 - val_activation_4_loss: 3.8690 - val_activation_5_loss: 5.4965\n",
      "ITERATION: 51 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9419 - activation_4_loss: 0.9457 - activation_5_loss: 2.3442 - dense_loss: 0.4488\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0434 - activation_4_loss: 0.0288 - activation_5_loss: 0.0146 - val_loss: 9.3366 - val_activation_4_loss: 3.8645 - val_activation_5_loss: 5.4722\n",
      "ITERATION: 52 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4075 - activation_4_loss: 1.3388 - activation_5_loss: 1.5809 - dense_loss: 0.4004\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1510 - activation_4_loss: 0.1253 - activation_5_loss: 0.0257 - val_loss: 9.3168 - val_activation_4_loss: 3.8651 - val_activation_5_loss: 5.4517\n",
      "ITERATION: 53 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9408 - activation_4_loss: 1.5651 - activation_5_loss: 1.9797 - dense_loss: 0.2333\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0852 - activation_4_loss: 0.0726 - activation_5_loss: 0.0126 - val_loss: 9.2916 - val_activation_4_loss: 3.8641 - val_activation_5_loss: 5.4275\n",
      "ITERATION: 54 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.9547 - activation_4_loss: 1.9418 - activation_5_loss: 1.5677 - dense_loss: 0.2781\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0416 - activation_4_loss: 0.0240 - activation_5_loss: 0.0176 - val_loss: 9.2698 - val_activation_4_loss: 3.8647 - val_activation_5_loss: 5.4051\n",
      "ITERATION: 55 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2850 - activation_4_loss: 1.9796 - activation_5_loss: 2.4111 - dense_loss: 0.6117\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0447 - activation_4_loss: 0.0316 - activation_5_loss: 0.0131 - val_loss: 9.2551 - val_activation_4_loss: 3.8662 - val_activation_5_loss: 5.3889\n",
      "ITERATION: 56 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.5863 - activation_4_loss: 2.2662 - activation_5_loss: 2.5350 - dense_loss: 0.6414\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0525 - activation_4_loss: 0.0268 - activation_5_loss: 0.0258 - val_loss: 9.2358 - val_activation_4_loss: 3.8680 - val_activation_5_loss: 5.3679\n",
      "ITERATION: 57 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.8664 - activation_4_loss: 1.5319 - activation_5_loss: 2.5319 - dense_loss: 0.5763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step - loss: 0.0799 - activation_4_loss: 0.0515 - activation_5_loss: 0.0284 - val_loss: 9.2278 - val_activation_4_loss: 3.8735 - val_activation_5_loss: 5.3543\n",
      "ITERATION: 58 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.2819 - activation_4_loss: 1.7220 - activation_5_loss: 1.7005 - dense_loss: 1.6957\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1387 - activation_4_loss: 0.1128 - activation_5_loss: 0.0259 - val_loss: 9.2232 - val_activation_4_loss: 3.8769 - val_activation_5_loss: 5.3463\n",
      "ITERATION: 59 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6897 - activation_4_loss: 1.8932 - activation_5_loss: 1.0966 - dense_loss: 0.5818\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1131 - activation_4_loss: 0.0803 - activation_5_loss: 0.0327 - val_loss: 9.2230 - val_activation_4_loss: 3.8812 - val_activation_5_loss: 5.3418\n",
      "ITERATION: 60 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7005 - activation_4_loss: 1.3201 - activation_5_loss: 1.8745 - dense_loss: 0.3470\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0350 - activation_4_loss: 0.0216 - activation_5_loss: 0.0134 - val_loss: 9.2179 - val_activation_4_loss: 3.8813 - val_activation_5_loss: 5.3366\n",
      "ITERATION: 61 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.0936 - activation_4_loss: 1.8695 - activation_5_loss: 2.2298 - dense_loss: 0.8169\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1413 - activation_4_loss: 0.1176 - activation_5_loss: 0.0237 - val_loss: 9.2156 - val_activation_4_loss: 3.8787 - val_activation_5_loss: 5.3368\n",
      "ITERATION: 62 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.5267 - activation_4_loss: 1.6851 - activation_5_loss: 1.2418 - dense_loss: 0.3834\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0688 - activation_4_loss: 0.0566 - activation_5_loss: 0.0122 - val_loss: 9.2132 - val_activation_4_loss: 3.8761 - val_activation_5_loss: 5.3371\n",
      "ITERATION: 63 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6103 - activation_4_loss: 1.4340 - activation_5_loss: 1.3450 - dense_loss: 0.6179\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0489 - activation_4_loss: 0.0291 - activation_5_loss: 0.0199 - val_loss: 9.2235 - val_activation_4_loss: 3.8767 - val_activation_5_loss: 5.3468\n",
      "ITERATION: 64 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7549 - activation_4_loss: 1.0005 - activation_5_loss: 1.8127 - dense_loss: 0.7211\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0403 - activation_4_loss: 0.0235 - activation_5_loss: 0.0168 - val_loss: 9.2368 - val_activation_4_loss: 3.8781 - val_activation_5_loss: 5.3587\n",
      "ITERATION: 65 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.3748 - activation_4_loss: 1.5255 - activation_5_loss: 2.1746 - dense_loss: 0.5093\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1556 - activation_4_loss: 0.1321 - activation_5_loss: 0.0235 - val_loss: 9.2492 - val_activation_4_loss: 3.8784 - val_activation_5_loss: 5.3708\n",
      "ITERATION: 66 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.4922 - activation_4_loss: 1.5254 - activation_5_loss: 1.4055 - dense_loss: 0.3713\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1280 - activation_4_loss: 0.0931 - activation_5_loss: 0.0349 - val_loss: 9.2653 - val_activation_4_loss: 3.8792 - val_activation_5_loss: 5.3861\n",
      "ITERATION: 67 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1627 - activation_4_loss: 1.4185 - activation_5_loss: 1.3835 - dense_loss: 0.1562\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0579 - activation_4_loss: 0.0397 - activation_5_loss: 0.0181 - val_loss: 9.2842 - val_activation_4_loss: 3.8828 - val_activation_5_loss: 5.4014\n",
      "ITERATION: 68 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 4.5420 - activation_4_loss: 1.3946 - activation_5_loss: 2.0724 - dense_loss: 0.9343\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0565 - activation_4_loss: 0.0417 - activation_5_loss: 0.0148 - val_loss: 9.3014 - val_activation_4_loss: 3.8898 - val_activation_5_loss: 5.4116\n",
      "ITERATION: 69 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 5.6799 - activation_4_loss: 2.6890 - activation_5_loss: 2.3441 - dense_loss: 0.3939\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1183 - activation_4_loss: 0.1067 - activation_5_loss: 0.0116 - val_loss: 9.3141 - val_activation_4_loss: 3.8979 - val_activation_5_loss: 5.4162\n",
      "ITERATION: 70 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.7858 - activation_4_loss: 1.1906 - activation_5_loss: 1.4796 - dense_loss: 0.9696\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1184 - activation_4_loss: 0.0972 - activation_5_loss: 0.0212 - val_loss: 9.3352 - val_activation_4_loss: 3.9102 - val_activation_5_loss: 5.4250\n",
      "ITERATION: 71 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.9492 - activation_4_loss: 0.9995 - activation_5_loss: 1.3576 - dense_loss: 0.4204\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.1233 - activation_4_loss: 0.1065 - activation_5_loss: 0.0168 - val_loss: 9.3498 - val_activation_4_loss: 3.9203 - val_activation_5_loss: 5.4296\n",
      "ITERATION: 72 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.1471 - activation_4_loss: 1.5821 - activation_5_loss: 0.9645 - dense_loss: 0.4433\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0612 - activation_4_loss: 0.0530 - activation_5_loss: 0.0082 - val_loss: 9.3745 - val_activation_4_loss: 3.9356 - val_activation_5_loss: 5.4389\n",
      "ITERATION: 73 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.0306 - activation_4_loss: 1.2238 - activation_5_loss: 1.2651 - dense_loss: 0.3692\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.2551 - activation_4_loss: 0.2198 - activation_5_loss: 0.0353 - val_loss: 9.4079 - val_activation_4_loss: 3.9513 - val_activation_5_loss: 5.4566\n",
      "ITERATION: 74 of 75.\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 3.6864 - activation_4_loss: 1.3734 - activation_5_loss: 1.3043 - dense_loss: 0.6802\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0430 - activation_4_loss: 0.0301 - activation_5_loss: 0.0129 - val_loss: 9.4579 - val_activation_4_loss: 3.9713 - val_activation_5_loss: 5.4866\n"
     ]
    }
   ],
   "source": [
    "log_list = []\n",
    "\n",
    "batch_size = 12\n",
    "\n",
    "\n",
    "for ii in range(75):\n",
    "    print(f\"ITERATION: {ii} of 75.\")\n",
    "    \n",
    "#     valid_loss = model.evaluate((x_valid[0],\n",
    "#                             x_valid[1],\n",
    "#                             x_valid[2]),\n",
    "#                             y_valid,\n",
    "#                            verbose=1,\n",
    "#                            batch_size=36,\n",
    "#                            return_dict=True)\n",
    "#     pred_start, pred_end = model.predict((x_valid[0], x_valid[1], x_valid[2]), batch_size=36, verbose=1)\n",
    "#     valid_acc = merge_squad_results(valid_examples, pred_start, pred_end)[0]\n",
    "    \n",
    "#     print(f\"ACCURACY: {valid_acc}\")\n",
    "    \n",
    "#     validation_loss.append(valid_loss)\n",
    "#     validation_accuracy.append(valid_acc)\n",
    "#     batch.append(ii*2)\n",
    "    \n",
    "    span_ii = np.random.choice(range(x_span[0].shape[0]), batch_size, replace=True)\n",
    "    cat_ii = np.random.choice(range(x_cat[0].shape[0]), batch_size, replace=True)\n",
    "    \n",
    "    model_cat.fit(\n",
    "        (x_cat[0][cat_ii,:],\n",
    "         x_cat[1][cat_ii,:],\n",
    "         x_cat[2][cat_ii,:]),\n",
    "        (y_cat[0][cat_ii],\n",
    "         y_cat[1][cat_ii],\n",
    "         y_cat[2][cat_ii]),\n",
    "        epochs=1,  # For demonstration, 3 epochs are recommended\n",
    "        verbose=1,\n",
    "        batch_size=batch_size,  # Made this smaller. Bump up.\n",
    "    )\n",
    "    \n",
    "    log = model.fit(\n",
    "        (x_span[0][span_ii,:],\n",
    "         x_span[1][span_ii,:],\n",
    "         x_span[2][span_ii,:]),\n",
    "        (y_span[0][span_ii],\n",
    "         y_span[1][span_ii]),\n",
    "        epochs=1,  # For demonstration, 3 epochs are recommended\n",
    "        verbose=1,\n",
    "        batch_size=batch_size,  # Made this smaller. Bump up.\n",
    "        validation_data=((x_valid[0],\n",
    "                                        x_valid[1],\n",
    "                                        x_valid[2]),\n",
    "                                        y_valid[0]),\n",
    "                    validation_batch_size=36\n",
    "    )\n",
    "  \n",
    "    log_list.append(log.history)\n",
    "    \n",
    "# valid_loss = model.evaluate((x_valid[0],\n",
    "#                             x_valid[1],\n",
    "#                             x_valid[2]),\n",
    "#                             y_valid[0],\n",
    "#                            verbose=1,\n",
    "#                            batch_size=36,\n",
    "#                            return_dict=True)\n",
    "\n",
    "# pred_start, pred_end = model.predict((x_valid[0], x_valid[1], x_valid[2]), batch_size=36, verbose=1)\n",
    "# valid_acc = merge_squad_results(valid_examples, pred_start, pred_end)[0]\n",
    "\n",
    "# validation_loss.append(valid_loss)\n",
    "# validation_accuracy.append(valid_acc)\n",
    "# batch.append(ii*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ben/anaconda3/envs/distant_crowds/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: roberta_base_squad2_512in_cccspans_sizecats_softspans_75ii/assets\n",
      "INFO:tensorflow:Assets written to: roberta_base_squad2_512in_cccspans_sizecats_softspans_75ii_auxiliary/assets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "stats = pd.DataFrame(log_list)\n",
    "stats.to_csv(\"results/roberta_base_squad2_512in_cccspans_sizecats_softspans_75ii.csv\")\n",
    "model.save(\"roberta_base_squad2_512in_cccspans_sizecats_softspans_75ii\")\n",
    "model_cat.save(\"roberta_base_squad2_512in_cccspans_sizecats_softspans_75ii_auxiliary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 6s 275ms/step\n",
      "92/92 [==============================] - 27s 299ms/step\n",
      "Validation set accuracy (EM): 0.72\n",
      "Test set accuracy (EM): 0.652972972972973\n",
      "Validation set F1: 0.6737777777777778\n",
      "Test set F1: 0.6389609427980859\n"
     ]
    }
   ],
   "source": [
    "pred_start_v, pred_end_v = model.predict((x_valid[0], x_valid[1], x_valid[2]), batch_size=36, verbose=1)\n",
    "valid_acc = merge_squad_results(valid_examples, pred_start_v, pred_end_v)\n",
    "\n",
    "pred_start_t, pred_end_t = model.predict((x_test[0], x_test[1], x_test[2]), batch_size=36, verbose=1)\n",
    "test_acc = merge_squad_results(test_examples, pred_start_t, pred_end_t)\n",
    "\n",
    "print(f\"Validation set accuracy (EM): {valid_acc[0]}\")\n",
    "print(f\"Test set accuracy (EM): {test_acc[0]}\")\n",
    "print(f\"Validation set F1: {valid_acc[1]}\")\n",
    "print(f\"Test set F1: {test_acc[1]}\")\n",
    "\n",
    "pd.DataFrame([{\"model\":\"roberta_base_squad2_512in_cccspans_sizecats_softspans_75ii\",\n",
    "              \"f1_valid\":valid_acc[1],\"f1_test\":test_acc[1],\n",
    "              \"em_valid\":valid_acc[0],\"em_test\":test_acc[0]}]).to_csv(\"results/roberta_f1v_f1t_emv_emt.csv\",mode=\"a\",header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:distant_crowds]",
   "language": "python",
   "name": "conda-env-distant_crowds-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
